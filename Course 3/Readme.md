# Data Science Methodology

![]()

## FlowChart
![](https://github.com/FacuJulia/IBM-Data-Science-Professional-Certificate/blob/main/Course%203/img/Datascience_methodology_flowchart.png)

## Cross-Industry Standard Process for Data Mining (CRISP-DM)
* [Methodology CRISP-DM](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%201/CRISP-DM.md.html?origin=www.coursera.org)
* [Intro CRISP-DM](https://www.ibm.com/docs/en/spss-modeler/saas?topic=dm-crisp-help-overview)

![](https://github.com/FacuJulia/IBM-Data-Science-Professional-Certificate/blob/main/Course%203/img/crisp_process.jpg)

## Module 1: From Problem to Approach and from Requirements to Collection
* **Business Understanding:** Helps to clarify the goals of the entity (Lab 1).
* **Analytic Approach:** Helps to identify what type of patterns will be needed to answer the questions most effectively (Lab 1).
* **Data Requirements:** The analytic methods to be used require certain data content, formats and representations, guided by domain knowledge (Lab 2).
* **Data Collection:** Data scientists identify and gather the available data resources. These can be in the form of structured, unstructured, and even semi-structured data relevant to the problem domain. Example: Web Scraping (Lab 2).

## Module 2: From Understanding to Preparation and from Modeling to Evaluation
* **Data Understanding:** Helps to construct the data set, verify if the data that you collected is representative of the problem to be solved. Use correlations to see how closely certain variables are related, use histograms of the variables to understand their distributions. Verify if any "missing value" mean anything (Lab 3).
* **Data Preparation:** Handling with missing or invalid values and remove duplicates, correct data format. Apply Feature engineering, create features that make the machine learning algorithms work. Is the most time-consuming phase of a data science project (Lab 3).
* **Modeling:** Focuses on developing models that are either descriptive or predictive, use a training set for predictive modelling, historical data which the outcomes are already known, acts like a gauge to determine if the model needs to be calibrated (Lab 4).
* **Evaluation:** The modeling and evaluation stages are done iteratively. Allows the quality of the model to be assessed but it's also an opportunity to see if it meets the initial request. (Phases: Diagnostic measures and statistical significance testing). The optimal model is the one giving the maximum separation between ROC curve relative to base line. It's a useful diagnostic tool in determining the optimal classification model (Lab 4).

## Module 3: From Deployment to Feedback
* **Deployment:**
* **Feedback:**

